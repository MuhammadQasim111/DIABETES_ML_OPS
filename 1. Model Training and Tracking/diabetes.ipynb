{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e35b08f",
   "metadata": {},
   "source": [
    "# Diabetes Prediction ML Project\n",
    "## End-to-End Machine Learning Project for MLOps\n",
    "\n",
    "This notebook contains the complete workflow for diabetes prediction using multiple ML algorithms and MLflow tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2793c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib & Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os\n",
    "import scipy as sp\n",
    "import gc\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV, BayesianRidge, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datasets\n",
    "!ls ../datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac57571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../datasets/diabetes_binary_5050split_health_indicators_BRFSS2015.csv.zip\")\n",
    "print(f\"Data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa01517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "df.rename(columns={\"Diabetes_012\":\"Diabetes_binary\"}, inplace=True)\n",
    "train = df.drop('Diabetes_binary', axis=1)\n",
    "targets = df.loc[:, \"Diabetes_binary\"]\n",
    "print(f\"Training data shape: {train.shape}\")\n",
    "print(f\"Target shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e4457",
   "metadata": {},
   "source": [
    "## Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow configuration\n",
    "os.environ[\"AWS_PROFILE\"] = \"your_aws_profile\"  # Change this to your AWS profile\n",
    "TRACKING_SERVER_HOST = \"localhost\"  # Change to your tracking server host\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "mlflow.set_experiment(\"diabetes_experiment_main\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "models = {\n",
    "    \"rf\": RandomForestClassifier(n_jobs=-1), \n",
    "    \"lgbm\": LGBMClassifier(n_jobs=-1),\n",
    "    \"xgb\": XGBClassifier(n_jobs=-1), \n",
    "    \"cb\": CatBoostClassifier(silent=True)\n",
    "}\n",
    "\n",
    "RANDOM_STATE = 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f341813",
   "metadata": {},
   "source": [
    "## Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_training(df, target_name, num_folds, model, debug=False, params=None):\n",
    "    \"\"\"\n",
    "    K-fold cross validation training with MLflow tracking\n",
    "    \"\"\"\n",
    "    with mlflow.start_run():\n",
    "        FOLDS = num_folds\n",
    "        \n",
    "        mlflow.set_tag(\"Developer\", \"MLOps_Student\")\n",
    "        mlflow.log_param(\"Train Data\", \"datasets/diabetes_binary_5050split_health_indicators_BRFSS2015.csv.zip\")\n",
    "        mlflow.log_param(\"RANDOM_STATE\", RANDOM_STATE)\n",
    "        mlflow.log_param(\"FOLDS\", FOLDS)\n",
    "        mlflow.log_param(\"Models\", str(models[model]))\n",
    "        \n",
    "        train_df = df.drop(target_name, axis=1)\n",
    "        target = df.loc[:, target_name]\n",
    "        \n",
    "        print(\"Starting Training. Train shape: {}\".format(train_df.shape))\n",
    "        gc.collect()\n",
    "        \n",
    "        # Cross validation\n",
    "        folds = KFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        oof_preds = np.zeros(train_df.shape[0])\n",
    "        \n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, target)):    \n",
    "            train_x, train_y = train_df.iloc[train_idx], target.iloc[train_idx]\n",
    "            valid_x, valid_y = train_df.iloc[valid_idx], target.iloc[valid_idx]\n",
    "            \n",
    "            # Train model\n",
    "            clf = models[model]\n",
    "            clf.fit(train_x, train_y)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = clf.predict(valid_x)\n",
    "            oof_preds[valid_idx] = y_pred\n",
    "            \n",
    "            f_score = f1_score(valid_y, oof_preds[valid_idx])\n",
    "            accuracy = accuracy_score(valid_y, oof_preds[valid_idx])\n",
    "            \n",
    "            print(f'---------> Fold {n_fold + 1} {f_score}')\n",
    "            \n",
    "            del train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "        \n",
    "        # Calculate final scores\n",
    "        score = f1_score(target, oof_preds)\n",
    "        full_accuracy_score = accuracy_score(target, oof_preds)\n",
    "        \n",
    "        mlflow.log_metric(\"f1_score\", score)\n",
    "        mlflow.log_metric(\"accuracy\", full_accuracy_score)\n",
    "        print('Full F1 Score score %.8f' % score)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a3bb21",
   "metadata": {},
   "source": [
    "## Model Training and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fee1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "kfold_training(df=df, target_name='Diabetes_binary', num_folds=3, model=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM\n",
    "kfold_training(df=df, target_name='Diabetes_binary', num_folds=3, model=\"lgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CatBoost\n",
    "kfold_training(df=df, target_name='Diabetes_binary', num_folds=3, model=\"cb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a93236",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e9962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "RANDOM_STATE = 1111\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbea857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Hyperparameter optimization objective function\n",
    "    \"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"Developer\", \"MLOps_Student\")\n",
    "        mlflow.log_param(\"Train Data\", \"datasets/diabetes_binary_5050split_health_indicators_BRFSS2015.csv.zip\")\n",
    "        mlflow.log_param(\"RANDOM_STATE\", RANDOM_STATE)\n",
    "        mlflow.log_param(\"FOLDS\", FOLDS)\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"Models\", \"LightGBM\")\n",
    "        \n",
    "        train_df = df.drop('Diabetes_binary', axis=1)\n",
    "        target = df.loc[:, 'Diabetes_binary']\n",
    "        \n",
    "        print(\"Starting Training. Train shape: {}\".format(train_df.shape))\n",
    "        gc.collect()\n",
    "        \n",
    "        folds = KFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        oof_preds = np.zeros(train_df.shape[0])\n",
    "        \n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, target)):    \n",
    "            train_x, train_y = train_df.iloc[train_idx], target.iloc[train_idx]\n",
    "            valid_x, valid_y = train_df.iloc[valid_idx], target.iloc[valid_idx]\n",
    "            \n",
    "            train = lgb.Dataset(train_x, label=train_y)\n",
    "            valid = lgb.Dataset(valid_x, label=valid_y)\n",
    "            \n",
    "            booster = lgb.train(\n",
    "                params=params,\n",
    "                train_set=train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=valid,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            \n",
    "            y_pred = booster.predict(valid_x, raw_score=False)\n",
    "            y_pred = np.round(y_pred)\n",
    "            oof_preds[valid_idx] = y_pred\n",
    "            \n",
    "            f_score = f1_score(valid_y, oof_preds[valid_idx])\n",
    "            print(f'---------> Fold {n_fold + 1} {f_score}')\n",
    "            \n",
    "            del booster, train_x, train_y, valid_x, valid_y\n",
    "            gc.collect()\n",
    "        \n",
    "        score = f1_score(target, oof_preds)\n",
    "        full_accuracy_score = accuracy_score(target, oof_preds)\n",
    "        \n",
    "        mlflow.log_metric(\"f1_score\", score)\n",
    "        mlflow.log_metric(\"accuracy\", full_accuracy_score)\n",
    "        print('Full F1 Score score %.8f' % score)\n",
    "        \n",
    "        return {'loss': -score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25686f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for hyperparameter optimization\n",
    "search_space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 3, 15, 1)),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 1, 10),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Uncomment to run hyperparameter optimization\n",
    "# trials = Trials()\n",
    "# best = fmin(fn=objective, space=search_space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "# print(f\"Best parameters: {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6d0c1",
   "metadata": {},
   "source": [
    "## Best Model Training and Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "best_params = {\n",
    "    'learning_rate': 0.10552983694225122,\n",
    "    'max_depth': 89,\n",
    "    'min_child_weight': 1.704681566723118,\n",
    "    'reg_alpha': 0.010202520050703611,\n",
    "    'reg_lambda': 0.046206444839271325,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"Developer\", \"MLOps_Student\")\n",
    "    mlflow.log_param(\"Train Data\", \"datasets/diabetes_binary_5050split_health_indicators_BRFSS2015.csv.zip\")\n",
    "    mlflow.log_param(\"RANDOM_STATE\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"FOLDS\", 5)\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_param(\"Models\", \"LightGBM_Best\")\n",
    "    \n",
    "    # Train final model\n",
    "    train_data = lgb.Dataset(train, label=targets)\n",
    "    final_model = lgb.train(\n",
    "        params=best_params,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=1000\n",
    "    )\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.lightgbm.log_model(final_model, artifact_path=\"models\")\n",
    "    print(f\"Model artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    print(\"Model training completed and logged to MLflow!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
